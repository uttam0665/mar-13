{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d616d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\"\"\"\n",
    "\n",
    "Ans:-\n",
    "    \n",
    "    ANOVA (Analysis of Variance) relies on several assumptions to ensure the validity of its results. These assumptions are as follows:\n",
    "\n",
    "Independence of observations: The observations within each group should be independent of each other. This means that the values of one observation should not be influenced by or dependent on the values of other observations within the same group. Violations of this assumption can occur in various ways, such as in repeated measures designs where observations from the same participant are not independent or in clustered data where observations from the same cluster are correlated.\n",
    "\n",
    "Homogeneity of variance (homoscedasticity): The variances of the dependent variable should be equal across all groups being compared. In other words, the spread or dispersion of the data points should be similar for each group. Violations of this assumption, known as heteroscedasticity, can lead to biased results. For example, if the variance is much larger in one group compared to others, it can lead to an overestimation of the differences between groups.\n",
    "\n",
    "Normality of residuals: The residuals (the differences between observed and predicted values) should follow a normal distribution. This assumption refers to the distribution of the errors or discrepancies between the observed data and the model's predictions. Violations of this assumption can occur when the residuals deviate from a normal distribution, such as when they are skewed or have heavy tails. Departures from normality can impact the accuracy of statistical inference and the interpretation of results.\n",
    "\n",
    "Independence of errors: The errors or residuals should be independent of each other. This assumption assumes that there is no systematic pattern or correlation in the errors. Violations of this assumption can occur when there is autocorrelation, meaning that the errors at one observation are related to the errors at neighboring observations. This can occur, for example, in time series data or spatially correlated data.\n",
    "\n",
    "Violations of these assumptions can impact the validity of ANOVA results. For example:\n",
    "\n",
    "Violations of independence can lead to biased standard errors, confidence intervals, and p-values. In a repeated measures design, where observations from the same participant are correlated, ignoring the dependence can inflate the Type I error rate.\n",
    "\n",
    "Violations of homogeneity of variance can affect the efficiency of the ANOVA, making it more challenging to detect true differences between groups. It can also lead to incorrect conclusions if the group with larger variances dominates the results.\n",
    "\n",
    "Violations of normality of residuals can affect the accuracy of hypothesis tests and confidence intervals. Non-normality may distort p-values and impact the power of the analysis, leading to incorrect conclusions.\n",
    "\n",
    "Violations of independence of errors can lead to incorrect standard errors and hypothesis tests. Ignoring autocorrelation in the errors can lead to underestimation or overestimation of the true significance of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fc400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q2. What are the three types of ANOVA, and in what situations would each be used?\"\"\"\n",
    "Ans:-\n",
    "    \n",
    "The three types of ANOVA are:\n",
    "\n",
    "1.One-Way ANOVA: One-Way ANOVA is used when comparing the means of three or more groups that are classified into a single categorical independent variable (also known as a factor). It tests whether there are any significant differences in the means of the groups. One-Way ANOVA is appropriate when there is only one factor being tested, such as comparing the effectiveness of different treatments or studying the impact of different teaching methods on student performance.\n",
    "\n",
    "2.Two-Way ANOVA: Two-Way ANOVA is used when there are two independent categorical variables (factors) and you want to analyze their main effects and interaction effect on a continuous dependent variable. It examines whether there are significant differences in the means of the dependent variable across different levels of each factor and investigates if there is an interaction between the two factors. Two-Way ANOVA is suitable when studying the effects of multiple factors simultaneously, such as evaluating the impact of both gender and age group on a test score.\n",
    "\n",
    "3.N-Way ANOVA (Factorial ANOVA): N-Way ANOVA, also known as Factorial ANOVA, is used when there are more than two independent categorical variables (factors). It allows for the examination of main effects and interaction effects among multiple factors on a continuous dependent variable. N-Way ANOVA is suitable when there are multiple factors of interest and you want to investigate their individual effects as well as the potential interactions among them. For example, studying the effects of different factors like treatment, gender, and age group on patient recovery time.\n",
    "\n",
    "Each type of ANOVA is used to address different research questions and analyze data with varying designs. It is important to select the appropriate type of ANOVA based on the specific research design, the number of factors being investigated, and the nature of the variables involved.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "One-Way ANOVA: One-Way ANOVA is used when comparing the means of three or more groups that are classified into a single categorical independent variable (also known as a factor). It tests whether there are any significant differences in the means of the groups. One-Way ANOVA is appropriate when there is only one factor being tested, such as comparing the effectiveness of different treatments or studying the impact of different teaching methods on student performance.\n",
    "\n",
    "Two-Way ANOVA: Two-Way ANOVA is used when there are two independent categorical variables (factors) and you want to analyze their main effects and interaction effect on a continuous dependent variable. It examines whether there are significant differences in the means of the dependent variable across different levels of each factor and investigates if there is an interaction between the two factors. Two-Way ANOVA is suitable when studying the effects of multiple factors simultaneously, such as evaluating the impact of both gender and age group on a test score.\n",
    "\n",
    "N-Way ANOVA (Factorial ANOVA): N-Way ANOVA, also known as Factorial ANOVA, is used when there are more than two independent categorical variables (factors). It allows for the examination of main effects and interaction effects among multiple factors on a continuous dependent variable. N-Way ANOVA is suitable when there are multiple factors of interest and you want to investigate their individual effects as well as the potential interactions among them. For example, studying the effects of different factors like treatment, gender, and age group on patient recovery time.\n",
    "\n",
    "Each type of ANOVA is used to address different research questions and analyze data with varying designs. It is important to select the appropriate type of ANOVA based on the specific research design, the number of factors being investigated, and the nature of the variables involved.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\"\"\"\n",
    "#Ans:-\n",
    "\n",
    "The partitioning of variance in ANOVA refers to the division of the total variation in the data into different sources or components, namely the between-group variation and the within-group variation. This partitioning helps in understanding the sources of variation and their contributions to the overall variability observed in the data.\n",
    "\n",
    "In ANOVA, the total variation is decomposed into the following components:\n",
    "\n",
    "1.Between-group variation (explained variation): This component represents the variation in the data that is attributed to the differences between the groups being compared. It quantifies the extent to which the group means differ from each other. A large between-group variation suggests that the groups are distinct and have different means.\n",
    "\n",
    "2.Within-group variation (unexplained variation): This component represents the variation within each group. It captures the random variability or noise that cannot be explained by the differences between the groups. It includes individual differences, measurement error, and other unexplained factors. A small within-group variation suggests that the observations within each group are relatively homogeneous.\n",
    "\n",
    "Understanding the partitioning of variance in ANOVA is important for several reasons:\n",
    "\n",
    "a.Identifying group differences: By partitioning the total variation into between-group and within-group components, ANOVA helps determine if there are significant differences between the groups being compared. The between-group variation provides evidence for the presence of group differences, while the within-group variation indicates the level of random variability.\n",
    "\n",
    "b.Assessing the effect size: The partitioning of variance allows for the calculation of effect size measures such as eta-squared (η²) or partial eta-squared (η²p). These measures quantify the proportion of the total variation that is explained by the between-group variation, providing insights into the magnitude of the group differences.\n",
    "\n",
    "c.Guiding further analysis: Understanding the partitioning of variance can guide subsequent analysis, such as post hoc tests or follow-up comparisons, to identify which specific groups differ significantly from each other.\n",
    "\n",
    "d.Experimental design and interpretation: Knowledge of the partitioning of variance can inform experimental design, such as sample size determination and power analysis. It also helps in interpreting the results of studies and provides a more comprehensive understanding of the factors contributing to the observed effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf93a151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 73.33333333333333\n",
      "Explained sum of squares (SSE): 30.0\n",
      "Residual sum of squares (SSR): 43.33333333333333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\"\"\"\n",
    "#ans:-\n",
    "#To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, you can use the scipy.stats and numpy libraries. \n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "group1 = [10, 12, 8, 9, 11]\n",
    "group2 = [15, 13, 11, 12, 14]\n",
    "group3 = [9, 8, 10, 11, 7]\n",
    "\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "mean_total = np.mean(data)\n",
    "sst = np.sum((data - mean_total) ** 2)\n",
    "\n",
    "mean_group1 = np.mean(group1)\n",
    "mean_group2 = np.mean(group2)\n",
    "mean_group3 = np.mean(group3)\n",
    "sse = np.sum((group1 - mean_group1) ** 2) + np.sum((group2 - mean_group2) ** 2) + np.sum((group3 - mean_group3) ** 2)\n",
    "\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total sum of squares (SST):\", sst)\n",
    "print(\"Explained sum of squares (SSE):\", sse)\n",
    "print(\"Residual sum of squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a87022f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects:\n",
      "Factor2     4.666667\n",
      "Factor1    24.000000\n",
      "Name: sum_sq, dtype: float64\n",
      "Interaction effect:\n",
      "3.99999999999999\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\"\"\"\n",
    "#Ans:-\n",
    "    \n",
    "#In a two-way ANOVA, the main effects and interaction effects can be calculated using Python with the help of statistical libraries such as statsmodels or scipy.\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = {\n",
    "    'Factor1': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "    'Factor2': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Response': [10, 15, 12, 8, 11, 14, 9, 10, 13]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "model = ols('Response ~ Factor1 + Factor2 + Factor1:Factor2', data=df).fit()\n",
    "\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "main_effects = anova_table['sum_sq'][0:2]\n",
    "interaction_effect = anova_table['sum_sq'][2]\n",
    "\n",
    "print(\"Main effects:\")\n",
    "print(main_effects)\n",
    "\n",
    "print(\"Interaction effect:\")\n",
    "print(interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\"\"\"\n",
    "\n",
    "#ans:-\n",
    "\n",
    "When conducting a one-way ANOVA, the F-statistic and p-value provide information about the differences between the groups and the statistical significance of these differences. In the given scenario with an F-statistic of 5.23 and a p-value of 0.02, we can make the following conclusions:\n",
    "\n",
    "Differences between the groups: The obtained F-statistic of 5.23 indicates that there are differences between the means of the groups being compared. The F-statistic represents the ratio of the variation between the groups to the variation within the groups. A larger F-statistic suggests larger differences between the group means.\n",
    "\n",
    "Statistical significance: The p-value of 0.02 indicates that the probability of observing such a significant difference in group means by chance alone, assuming the null hypothesis is true, is 0.02 or 2%. Typically, a predetermined significance level (e.g., α = 0.05) is used as a threshold. In this case, the obtained p-value is smaller than the significance level, suggesting that the observed differences are statistically significant.\n",
    "\n",
    "Interpreting the results:\n",
    "Based on the results, we can conclude that there are statistically significant differences between the groups being compared. However, it is essential to consider the specific context and the research question to provide a meaningful interpretation. The observed differences between the groups indicate that there are variations in the outcome variable across the groups. The significance of these differences suggests that the group means are unlikely to be equal due to chance alone.\n",
    "\n",
    "It is important to note that the ANOVA does not identify which specific group(s) differ significantly from each other. To determine the specific group differences, additional post-hoc tests (e.g., Tukey's HSD, Bonferroni correction) or pairwise comparisons can be conducted.\n",
    "\n",
    "Overall, the obtained F-statistic and p-value in this scenario provide evidence for the presence of statistically significant differences between the groups, indicating that the factor being studied has an effect on the outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ddc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\"\"\"\n",
    "\n",
    "Ans:-\n",
    "    \n",
    "    \n",
    "Thank you for the correction. You provided an accurate list of common post-hoc tests used after ANOVA and their typical use cases. Here's a recap of the post-hoc tests and their applications:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD): Suitable for comparing all possible pairs of group means and controlling the family-wise error rate. It is commonly used when you have several groups and want to identify which specific pairs of groups differ significantly.\n",
    "\n",
    "Bonferroni correction: Adjusts the significance level to maintain the overall family-wise error rate. It is useful when conducting multiple pairwise comparisons, and it divides the desired significance level by the number of comparisons being made.\n",
    "\n",
    "Scheffé's method: A more conservative test that controls the family-wise error rate for all possible pairwise comparisons. It is appropriate when the number of groups is relatively small, and you want to maintain a stringent control on Type I error rates.\n",
    "\n",
    "Dunnett's test: Used when there is one control group and multiple treatment groups. It compares each treatment group to the control group, adjusting for multiple comparisons. Dunnett's test is suitable when you want to determine if any of the treatment groups differ significantly from the control group.\n",
    "\n",
    "Games-Howell test: A robust test used when the assumption of equal variances among groups is violated. It performs pairwise comparisons while adjusting for unequal variances. The Games-Howell test is suitable when you have unequal variances and need to identify which specific pairs of groups differ significantly.\n",
    "\n",
    "Duncan's multiple range test: A conservative test used to compare group means in a hierarchical or nested design. It provides confidence intervals for pairwise mean differences and identifies which groups differ significantly. Duncan's test is appropriate when you have a hierarchical or nested structure in your design.\n",
    "\n",
    "These post-hoc tests help to perform more detailed analyses after obtaining significant results in an ANOVA, allowing for comparisons between specific group means and identifying significant differences.\n",
    "The choice of the post-hoc test depends on the specific characteristics of the data, the research design, and the desired control over Type I error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2509995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\"\"\"\n",
    "\n",
    "#Ans:-\n",
    "\n",
    "After conducting an ANOVA and finding a significant result, post-hoc tests are often performed to determine which specific group means differ significantly from each other. Here are some common post-hoc tests used after ANOVA and their typical use cases:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD): Tukey's HSD test is widely used when comparing all possible pairs of group means. It controls the family-wise error rate and provides confidence intervals for pairwise mean differences.\n",
    "Tukey's HSD is appropriate when you have several groups and want to identify which specific pairs of groups differ significantly.\n",
    "\n",
    "Bonferroni correction: The Bonferroni correction adjusts the significance level to maintain an overall family-wise error rate. It is commonly used when conducting multiple pairwise comparisons. The Bonferroni correction divides the desired significance level by the number of comparisons being made. \n",
    "It is conservative but ensures a lower probability of false positives.\n",
    "\n",
    "Scheffé's method: Scheffé's method is a more conservative post-hoc test that controls the family-wise error rate for all possible pairwise comparisons. It is useful when the number of groups is relatively small, and you want to maintain a stringent control on Type I error rates.\n",
    "\n",
    "Dunnett's test: Dunnett's test is used when there is one control group and multiple treatment groups. It compares each treatment group to the control group, adjusting for multiple comparisons. Dunnett's test is appropriate when you want to determine if any of the treatment groups differ significantly from the control group.\n",
    "\n",
    "Games-Howell test: The Games-Howell test is a robust post-hoc test used when the assumption of equal variances among groups is violated. It performs pairwise comparisons while adjusting for unequal variances. The Games-Howell test is suitable when you have unequal variances and need to identify which specific pairs of groups differ significantly.\n",
    "\n",
    "Duncan's multiple range test: Duncan's test is a conservative post-hoc test used to compare group means in a hierarchical or nested design. It provides confidence intervals for pairwise mean differences and identifies which groups differ significantly. Duncan's test is appropriate when you have a hierarchical or nested structure in your design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6eb5c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 23.01597829363883\n",
      "P-value: 2.1211987234843963e-09\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.\"\"\"\n",
    "\n",
    "#ans:-\n",
    "#To conduct a one-way ANOVA in Python to determine if there are any significant differences between the mean weight loss of three diets (A, B, and C), you can use the scipy.stats library. Here's an example of how you can perform the analysis and interpret the results:\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Weight loss data for the three diets\n",
    "diet_a = [3, 4, 5, 2, 3, 4, 3, 2, 4, 5, 2, 3, 4, 3, 2, 4, 5, 2, 3, 4, 3, 2, 4, 5, 2, 3, 4, 3, 2, 4, 5, 2, 3, 4, 3, 2, 4, 5, 2, 3, 4, 3, 2, 4, 5, 2, 3, 4, 3]\n",
    "diet_b = [2, 1, 3, 4, 2, 3, 4, 2, 1, 3, 4, 2, 3, 4, 2, 1, 3, 4, 2, 3, 4, 2, 1, 3, 4, 2, 3, 4, 2, 1, 3, 4, 2, 3, 4, 2, 1, 3, 4, 2, 3, 4, 2, 1, 3, 4, 2, 3, 4]\n",
    "diet_c = [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1]\n",
    "\n",
    "f_statistic, p_value = stats.f_oneway(diet_a, diet_b, diet_c)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ec74fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    sum_sq    df          F    PR(>F)\n",
      "Program               15.8   2.0   2.807107  0.066054\n",
      "Experience            36.1   1.0  12.827411  0.000571\n",
      "Program:Experience     9.8   2.0   1.741117  0.181592\n",
      "Residual             236.4  84.0        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.\"\"\"\n",
    "\n",
    "#Ans:-\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = {\n",
    "    'Program': ['A', 'B', 'C'] * 30,\n",
    "    'Experience': ['Novice', 'Experienced'] * 45,\n",
    "    'Time': [10, 12, 8, 9, 11, 7, 8, 10, 9, 13, 7, 11, 12, 10, 9, 8, 7, 11, 10, 12, 8, 9, 11, 7, 8, 10, 9, 13, 7, 11] * 3\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "model = ols('Time ~ Program + Experience + Program:Experience', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9276c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -1.1306019943221475\n",
      "P-value: 0.2730628837488593\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.\"\"\"\n",
    "\n",
    "#ans:=\n",
    "\n",
    "#conduct a two-sample t-test in Python to determine if there are any significant differences in test scores between the control group and the experimental group, you can use the scipy.stats library. Here's an example of how you can perform the analysis and conduct a post-hoc test if the results are significant:\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "control_scores = [75, 80, 85, 90, 70, 85, 80, 90, 95, 85]\n",
    "\n",
    "experimental_scores = [80, 85, 95, 90, 75, 90, 85, 85, 90, 95]\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    posthoc_ttest = stats.ttest_ind(control_scores, experimental_scores)\n",
    "    print(posthoc_ttest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f8c51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sum_sq    df         F    PR(>F)\n",
      "Store       15.8   2.0  2.434644  0.093579\n",
      "Residual   282.3  87.0       NaN       NaN\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "=================================================\n",
      "group1 group2 meandiff p-adj  lower  upper reject\n",
      "-------------------------------------------------\n",
      "     A      B     -0.3 0.7957 -1.409 0.809  False\n",
      "     A      C     -1.0 0.0858 -2.109 0.109  False\n",
      "     B      C     -0.7 0.2936 -1.809 0.409  False\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a posthoc test to determine which store(s) differ significantly from each other.\n",
    "\"\"\"\n",
    "\n",
    "#Ans:-\n",
    "\n",
    "\n",
    "#To conduct a repeated measures ANOVA in Python to determine if there are any significant differences in sales between the three stores, you can use the statsmodels library. Here's an example of how you can perform the analysis and conduct post hoc tests\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "data = {\n",
    "    'Store': ['A', 'B', 'C'] * 30,\n",
    "    'Sales': [10, 12, 8, 9, 11, 7, 8, 10, 9, 13, 7, 11, 12, 10, 9, 8, 7, 11, 10, 12, 8, 9, 11, 7, 8, 10, 9, 13, 7, 11] * 3\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "model = ols('Sales ~ Store', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)\n",
    "\n",
    "posthoc = pairwise_tukeyhsd(df['Sales'], df['Store'])\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025bcd70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
